{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c8385e9-dc0f-4cbc-ae4c-da8a5c918176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2427"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch_geometric\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, Embedding\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "#print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc4dcd4a-b913-46ab-ae4a-b5d7eb682b8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = torch.load(\"data/act-mooc/graph.pt\")\n",
    "#data = torch.load(\"data/junyi/graph.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39f2d206-4bde-4025-95f0-e00518f5b99c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_hom = data.to_homogeneous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "759e88e9-306e-4559-b399-bfb8b74769d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 823498], node_id=[7144], edge_attr=[823498, 4], time=[823498], edge_y=[823498], node_type=[7144], edge_type=[823498], x=[7144, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_hom\n",
    "# no data features is implemented as just one random number drawn from normal\n",
    "data.x = torch.zeros(data.num_nodes, 1)\n",
    "data.edge_attr = data.edge_attr.float()\n",
    "data.time = data.time.float()\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36bfcac6-3e8b-4a14-bc24-248b8d584a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_node_ids = data.node_id[data.node_type==0].unique()\n",
    "min_times_per_node = {node_id: data.time[data.edge_index[0,:] == node_id].min() for node_id in unique_node_ids}\n",
    "\n",
    "# Subtract the minimum time from each node's times\n",
    "for node_id, min_time in min_times_per_node.items():\n",
    "    data.time[data.edge_index[0,:] == node_id] -= min_time\n",
    "    data.time[data.edge_index[1,:] == node_id] -= min_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9671e70-9d7e-4dc6-835b-d245453b86e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.node_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac7d35-9219-4242-929b-377c8f7a7085",
   "metadata": {},
   "source": [
    "node_type==1 are resources\n",
    "let's split randomly by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4f1f40b-5aae-4f0a-b112-33dfc9157859",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = data.time.cpu().numpy()\n",
    "quantile_70 = np.quantile(time_array, 0.7)\n",
    "quantile_85 = np.quantile(time_array, 0.85)\n",
    "\n",
    "# Create masks for splitting the data\n",
    "train_mask = time_array < quantile_70\n",
    "val_mask = time_array < quantile_85\n",
    "test_mask = np.ones_like(time_array, dtype=bool)\n",
    "\n",
    "# Function to create a new Data object from the original data and a mask\n",
    "def create_subset(data, mask):\n",
    "    # Filter data using the mask\n",
    "    subset = Data()\n",
    "    for key, item in data:\n",
    "        if key in ['node_id', 'node_type', 'x']:\n",
    "            subset[key] = item\n",
    "        elif key in ['edge_index']:\n",
    "            subset[key] = item[:,mask]\n",
    "        else:\n",
    "            subset[key] = item[mask]\n",
    "    return subset\n",
    "\n",
    "# Create subsets\n",
    "train_data = create_subset(data, train_mask)\n",
    "val_data = create_subset(data, val_mask)\n",
    "test_data = create_subset(data, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ecbb950-1a37-422a-92d6-431365d49702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_in_batches(edge_index, nodes, batch_size):\n",
    "    mask = torch.zeros(edge_index.size(1), dtype=torch.bool, device=device)\n",
    "    for i in range(0, len(nodes), batch_size):\n",
    "        batch_nodes = nodes[i:i + batch_size]\n",
    "        batch_mask = ((edge_index[0].unsqueeze(1) == batch_nodes).any(dim=1)) | \\\n",
    "                     ((edge_index[1].unsqueeze(1) == batch_nodes).any(dim=1))\n",
    "        mask |= batch_mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb49e10-f293-4464-8a57-c7a68555bda5",
   "metadata": {},
   "source": [
    "This class iterates over batches of users and returns all edges they are connected with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eee577e3-00f2-467e-a659-017f9106eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalLoader:\n",
    "    def __init__(self, data, start_time, batch_size=32):\n",
    "        self.data = data\n",
    "        self.time_order = torch.argsort(self.data.time)\n",
    "        self.start_time = start_time\n",
    "        self.start_index = torch.nonzero(self.data.time[self.time_order]>=start_time)[0]\n",
    "        self.index = self.start_index\n",
    "        self.batch_size = batch_size\n",
    "        self.length = len(data.edge_y) - self.start_index\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length // self.batch_size\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index + self.batch_size >= self.length:\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "\n",
    "        # these edges are predicted\n",
    "        mask = torch.zeros(self.data.edge_index.size(1), dtype=torch.bool).to(device)\n",
    "        mask[self.time_order[self.index+self.start_index:self.index+self.start_index+self.batch_size]] = 1\n",
    "\n",
    "        # but add neighbors that may be useful for the prediction = edges containing the same IDs in the time before\n",
    "        before_mask = torch.zeros(self.data.edge_index.size(1), dtype=torch.bool).to(device)\n",
    "        before_mask[self.time_order[:self.index+self.start_index]] = 1\n",
    "        first_time = self.data.time[self.time_order[self.index+self.start_index]]\n",
    "\n",
    "        edge_nodes = self.data.edge_index[:,mask].unique()\n",
    "        neighbor_mask = create_mask_in_batches(self.data.edge_index, edge_nodes, 256)\n",
    "\n",
    "        mask |= (neighbor_mask & before_mask)\n",
    "        \n",
    "        batch = create_subset(self.data, mask)\n",
    "        batch.edge_y[batch.time < first_time] = -1\n",
    "        self.index += self.batch_size\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df6dc7a1-75cc-4ab0-b254-9aad86600d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "train_loader = TemporalLoader(train_data, 0, batch_size=batch_size)\n",
    "val_loader = TemporalLoader(val_data, quantile_70, batch_size=batch_size)\n",
    "test_loader = TemporalLoader(test_data, quantile_85, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d9603e11-5fa3-4fdf-8d84-818ff1ac4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    assert batch.time[batch.edge_y>=0].min() >= quantile_70\n",
    "    assert batch.time[batch.edge_y>=0].max() < quantile_85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ea522f6-3c5d-4aba-b8e6-bf83218685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    assert batch.time[batch.edge_y>=0].min() >= quantile_85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b0bfb00-4a60-4e29-aab7-16f56d457ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7144, 50])\n",
      "torch.Size([512, 1])\n"
     ]
    }
   ],
   "source": [
    "class TimeEncoder(torch.nn.Module):\n",
    "    def __init__(self, time_dim):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.time_lin = Linear(1, time_dim)\n",
    "\n",
    "    def forward(self, t: Tensor):\n",
    "        return self.time_lin(t.view(-1, 1)).cos()\n",
    "\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_channels, out_channels, edge_dim, time_enc, resource_ids):\n",
    "        super().__init__()\n",
    "        self.conv1_user_to_resource = GATConv(emb_dim, hidden_channels, edge_dim=edge_dim)\n",
    "        self.conv1_resource_to_user = GATConv(emb_dim, hidden_channels, edge_dim=edge_dim)\n",
    "\n",
    "        self.conv2_user_to_resource = GATConv(hidden_channels, out_channels, edge_dim=edge_dim)\n",
    "        self.conv2_resource_to_user = GATConv(hidden_channels, out_channels, edge_dim=edge_dim)\n",
    "        self.time_enc = time_enc\n",
    "        self.mapping = {nid: i+1 for i, nid in enumerate(resource_ids)}\n",
    "        self.embedding = Embedding(len(resource_ids)+1, emb_dim)\n",
    "\n",
    "    def forward(self, node_id: Tensor, node_type: Tensor, edge_index: Tensor, edge_attr: Tensor, t: Tensor, edge_type: Tensor) -> Tensor:\n",
    "        # x: Node feature matrix of shape [num_nodes, in_channels]\n",
    "        # edge_index: Graph connectivity matrix of shape [2, num_edges]\n",
    "        # edge_attr: Edge features\n",
    "        # t: Timestamp of edges\n",
    "        time_enc = self.time_enc(t)\n",
    "        edge_attr = torch.cat([time_enc, edge_attr], dim=-1)\n",
    "        mask = edge_type == 0\n",
    "\n",
    "        node_ids = torch.tensor([self.mapping.get(nid, 0) for nid in node_id]).to(device)\n",
    "        x = self.embedding(node_ids)\n",
    "        x_resources = self.conv1_user_to_resource(x, edge_index[:, mask], edge_attr[mask]).relu()\n",
    "        x_users = self.conv1_resource_to_user(x, edge_index[:, ~mask], edge_attr[~mask]).relu()\n",
    "        users = node_type == 0\n",
    "        h = torch.zeros_like(x_users)\n",
    "        h[users] = x_users[users]\n",
    "        h[~users] = x_resources[~users]\n",
    "\n",
    "        h_resources = self.conv2_user_to_resource(h, edge_index[:, mask], edge_attr[mask]).relu()\n",
    "        h_users = self.conv2_resource_to_user(h, edge_index[:, ~mask], edge_attr[~mask]).relu()\n",
    "        o = torch.zeros_like(h_users)\n",
    "        o[users,:] = h_users[users,:]\n",
    "        o[~users,:] = h_resources[~users,:]\n",
    "        \n",
    "        return o\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        dim = 2 * in_channels + time_enc.time_dim # 2*\n",
    "        self.lin = Linear(dim, dim)\n",
    "        self.lin_final = Linear(dim, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst, t):\n",
    "        time_enc = self.time_enc(t)\n",
    "        input = torch.cat([z_src, z_dst, time_enc], dim=-1) # [z_src] # now only user and time embedding\n",
    "        h = self.lin(input)\n",
    "        h = h.relu()\n",
    "        \n",
    "        return self.lin_final(h)\n",
    "\n",
    "emb_dim = hidden_dim = time_dim = 50\n",
    "identity_dim = 50\n",
    "\n",
    "time_enc = TimeEncoder(time_dim).to(device)\n",
    "\n",
    "gnn = GATModel(identity_dim, hidden_dim, emb_dim, time_dim+data.edge_attr.size(1), time_enc, data.node_id[data.node_type == 1]).to(device)\n",
    "link_pred = LinkPredictor(emb_dim, time_enc).to(device)\n",
    "\n",
    "# Test forward run of the models\n",
    "batch = next(iter(train_loader)).to(device)\n",
    "train_loader.reset() # reset\n",
    "embs = gnn(batch.node_id, batch.node_type, batch.edge_index, batch.edge_attr, batch.time, batch.edge_type)\n",
    "print(embs.shape)\n",
    "link_preds = link_pred(embs[batch.edge_index[0]], embs[batch.edge_index[1]], batch.time)\n",
    "print(link_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "749fc235-4aee-4c67-b429-52838832d48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26600"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in gnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb196a3e-07b4-4b21-9d04-031d96fc6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(gnn, link_pred, time_enc):\n",
    "    gnn.eval()\n",
    "    link_pred.eval()\n",
    "    time_enc.eval()\n",
    "    scores = []\n",
    "    for batch in tqdm(test_loader, desc='Validation Batches'):\n",
    "        if (batch.edge_y>0).any():\n",
    "            mask = (batch.edge_y < 0)\n",
    "            node_embs = gnn(batch.node_id, batch.node_type, batch.edge_index[:,mask], batch.edge_attr[mask], batch.time[mask], batch.edge_type[mask])\n",
    "            mask = (batch.edge_y >= 0) & (batch.edge_type == 1)\n",
    "            link_preds = link_pred(node_embs[batch.edge_index[0,mask]], node_embs[batch.edge_index[1,mask]], batch.time[mask]).sigmoid()\n",
    "            #RocCurveDisplay.from_predictions(batch.edge_y.cpu(), link_preds.cpu())\n",
    "            #plt.show()\n",
    "            scores += [roc_auc_score(batch.edge_y[mask].cpu().numpy(), link_preds.cpu().numpy())]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339dd72-fbef-47f2-baa0-1c66f7cd8817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1125/1125 [00:49<00:00, 22.96it/s]\n",
      "Validation Batches: 100%|██████████| 241/241 [00:07<00:00, 34.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.20640122890472412, Test AUC: 0.4833717630479497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1125/1125 [00:48<00:00, 23.33it/s]\n",
      "Validation Batches: 100%|██████████| 241/241 [00:06<00:00, 34.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.19788284599781036, Test AUC: 0.6908669020238983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1125/1125 [00:48<00:00, 23.36it/s]\n",
      "Validation Batches:  89%|████████▉ | 214/241 [00:06<00:00, 40.90it/s]"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(set(time_enc.parameters()) | set(gnn.parameters()) | set(link_pred.parameters()), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(0, 20):\n",
    "    gnn.train()\n",
    "    link_pred.train()\n",
    "    time_enc.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc='Training Batches'):\n",
    "        batch.to(device)\n",
    "        # forward pass with edges that are older than this batch\n",
    "        mask = batch.edge_y < 0\n",
    "        node_embs = gnn(batch.node_id, batch.node_type, batch.edge_index[:,mask], batch.edge_attr[mask], batch.time[mask], batch.edge_type[mask])\n",
    "        \n",
    "        # first predict for all dropout edges\n",
    "        mask = (batch.edge_y == 1) & (batch.edge_type == 1)\n",
    "        positive_edges = batch.edge_index[:, mask]\n",
    "        if positive_edges.size(1) == 0: continue\n",
    "        pos_out = link_pred(node_embs[positive_edges[0]], node_embs[positive_edges[1]], batch.time[mask])\n",
    "        loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "\n",
    "        # sample the same number of 0 edges from edge_index\n",
    "        negative_indices = torch.nonzero((batch.edge_y == 0) & (batch.edge_type == 1)).squeeze()\n",
    "        negative_indices = negative_indices[torch.randperm(negative_indices.size(0))][:positive_edges.size(1)]\n",
    "        negative_edges = batch.edge_index[:, negative_indices]\n",
    "        neg_out = link_pred(node_embs[negative_edges[0]], node_embs[negative_edges[1]], batch.time[negative_indices])\n",
    "        loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "\n",
    "        # backward pass and gradient update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "\n",
    "    test_auc = test(gnn, link_pred, time_enc)\n",
    "    print(f'Epoch: {epoch}, Train Loss: {total_loss / train_data.edge_y.sum()}, Test AUC: {test_auc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7dba23-1a7c-4b16-9196-d6d52f7cf3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603e52c-07d6-4568-b7fc-3b97539668fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
