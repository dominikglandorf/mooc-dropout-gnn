{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8385e9-dc0f-4cbc-ae4c-da8a5c918176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import TimeEncoder, GATModel, LinkPredictor\n",
    "from helpers import TemporalLoader, create_mask_in_batches, create_subset, make_time_relative, prepare_data, append_to_csv\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731f504b-00d2-4f2d-994f-22c793fddfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(gnn, link_pred, time_enc, loader):\n",
    "    gnn.eval()\n",
    "    link_pred.eval()\n",
    "    time_enc.eval()\n",
    "\n",
    "    true_labels = torch.Tensor().to(device)\n",
    "    predictions = torch.Tensor().to(device)\n",
    "    batches = 0\n",
    "    for batch in tqdm(loader, desc='Batches'):\n",
    "        batches += 1\n",
    "        mask = (batch.edge_y < 0)\n",
    "        node_embs = gnn(batch.node_id, batch.node_type, batch.edge_index[:,mask], batch.edge_attr[mask], batch.time[mask], batch.edge_type[mask])\n",
    "        mask = (batch.edge_y >= 0) & (batch.edge_type == 1)\n",
    "        link_preds = link_pred(node_embs[batch.edge_index[0,mask]], node_embs[batch.edge_index[1,mask]], batch.time[mask]).sigmoid()\n",
    "\n",
    "        predictions = torch.cat((predictions, link_preds[:,0].detach()), dim=0)\n",
    "        true_labels = torch.cat((true_labels, batch.edge_y[mask]), dim=0)\n",
    "    if batches == 0:\n",
    "        return test(gnn, link_pred, time_enc, loader)\n",
    "    loss = criterion(predictions, true_labels)\n",
    "    auc = roc_auc_score(true_labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "    ap = average_precision_score(true_labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "    return loss, auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8433a9f7-4066-4c68-8ae8-88bdbdc4a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 2048\n",
    "num_epochs = 1\n",
    "emb_dim = 100\n",
    "hidden_dim = 100\n",
    "time_dim = 100\n",
    "identity_dim = 100\n",
    "learning_rate = 0.0001\n",
    "plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07370475-8432-4f26-9b57-7e43800bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental setting\n",
    "relative_times = [True, False]\n",
    "semi_transductives = [True, False]\n",
    "heterogenous_msg_passings = [True, False]\n",
    "dataset_paths = [\"data/act-mooc/graph.pt\"]\n",
    "#dataset_paths = sys.argv[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce7688-b31c-46e9-89c2-77f859a51985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    for relative_time, semi_transductive, heterogenous_msg_passing, dataset_path in itertools.product(relative_times, semi_transductives, heterogenous_msg_passings, dataset_paths):\n",
    "        print(f\"Combination: relative_time={relative_time}, semi_transductive={semi_transductive}, \"\n",
    "              f\"heterogenous_msg_passing={heterogenous_msg_passing}, dataset_path={dataset_path}\")\n",
    "        data = prepare_data(dataset_path, relative_time=False).to(device)\n",
    "        \n",
    "        time_array = data.time.cpu().numpy()\n",
    "        quantile_70 = np.quantile(time_array, 0.7)\n",
    "        quantile_85 = np.quantile(time_array, 0.85)\n",
    "        \n",
    "        # Create masks for splitting the data\n",
    "        train_mask = time_array < quantile_70\n",
    "        val_mask = time_array < quantile_85\n",
    "        test_mask = np.ones_like(time_array, dtype=bool)\n",
    "        \n",
    "        # Create subsets\n",
    "        train_data = create_subset(data, train_mask)\n",
    "        val_data = create_subset(data, val_mask)\n",
    "        test_data = create_subset(data, test_mask)\n",
    "        \n",
    "        train_loader = TemporalLoader(train_data, 0, device, batch_size=batch_size)\n",
    "        val_loader = TemporalLoader(val_data, quantile_70, device, batch_size=batch_size)\n",
    "        test_loader = TemporalLoader(test_data, quantile_85, device, batch_size=batch_size)\n",
    "\n",
    "        time_enc = TimeEncoder(time_dim).to(device)\n",
    "        gnn = GATModel(identity_dim, hidden_dim, emb_dim, time_dim+data.edge_attr.size(1), time_enc, data.node_id[data.node_type == 1], device, heterogenous_msg_passing, semi_transductive).to(device)\n",
    "        link_pred = LinkPredictor(emb_dim, time_enc).to(device)\n",
    "        optimizer = torch.optim.Adam(set(time_enc.parameters()) | set(gnn.parameters()) | set(link_pred.parameters()), lr=learning_rate)\n",
    "        num_params = sum(p.numel() for group in optimizer.param_groups for p in group[\"params\"] if p.requires_grad)\n",
    "        \n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_aucs = []\n",
    "        for epoch in range(0, num_epochs):\n",
    "            gnn.train()\n",
    "            link_pred.train()\n",
    "            time_enc.train()\n",
    "            losses = np.array([])\n",
    "            for batch in tqdm(train_loader, desc='Training Batches'):\n",
    "                batch.to(device)\n",
    "                # forward pass with edges that are older than this batch\n",
    "                mask = batch.edge_y < 0\n",
    "                node_embs = gnn(batch.node_id, batch.node_type, batch.edge_index[:,mask], batch.edge_attr[mask], batch.time[mask], batch.edge_type[mask])\n",
    "                \n",
    "                # first predict for all dropout edges\n",
    "                mask = (batch.edge_y == 1) & (batch.edge_type == 1)\n",
    "                positive_edges = batch.edge_index[:, mask]\n",
    "                if positive_edges.size(1) == 0: continue\n",
    "                pos_out = link_pred(node_embs[positive_edges[0]], node_embs[positive_edges[1]], batch.time[mask])\n",
    "                loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "        \n",
    "                # sample the same number of 0 edges from edge_index\n",
    "                negative_indices = torch.nonzero((batch.edge_y == 0) & (batch.edge_type == 1)).squeeze()\n",
    "                negative_indices = negative_indices[torch.randperm(negative_indices.size(0))][:positive_edges.size(1)]\n",
    "                negative_edges = batch.edge_index[:, negative_indices]\n",
    "                neg_out = link_pred(node_embs[negative_edges[0]], node_embs[negative_edges[1]], batch.time[negative_indices])\n",
    "                loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "        \n",
    "                # backward pass and gradient update\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses = np.append(losses, loss.detach().cpu()/2)\n",
    "\n",
    "            val_loss, val_auc, val_ap = test(gnn, link_pred, time_enc, val_loader)\n",
    "            train_losses.append(losses.mean())\n",
    "            val_losses.append(val_loss.detach().cpu())\n",
    "            val_aucs.append(val_auc)\n",
    "            print(f'Epoch: {epoch}, Train Loss: {losses.mean()}, Val Loss: {val_loss}, Val AUC: {val_auc}')\n",
    "        if plot:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(train_losses, label='Train Loss')\n",
    "            plt.plot(val_losses, label='Val Loss')\n",
    "            plt.plot(val_aucs, label='Val AUC')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training and Validation Loss Per Epoch')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        train_loss, train_auc, train_ap = test(gnn, link_pred, time_enc, train_loader)\n",
    "        test_loss, test_auc, test_ap = test(gnn, link_pred, time_enc, test_loader)\n",
    "        \n",
    "        append_to_csv(\"results.csv\", dataset_path, relative_time, semi_transductive, heterogenous_msg_passing,\n",
    "                      batch_size, num_epochs, learning_rate, emb_dim, hidden_dim, time_dim, identity_dim,\n",
    "                      train_loss.item(), val_loss.item(), test_loss.item(), train_auc, val_auc, test_auc, train_ap, val_ap, test_ap, i, num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74d7b1-41cf-4b2e-a4d9-cac781f6fe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
