{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a505e7-0fb5-494d-99eb-c8f75911b8a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.data import TemporalData\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "#from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "from torch_geometric.nn import TransformerConv\n",
    "#from torch_geometric.nn.models.tgn import (\n",
    "#    IdentityMessage,\n",
    "#    LastAggregator,\n",
    "#    LastNeighborLoader,\n",
    "#)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb8d1086-0980-420a-b846-494f185a59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import GRUCell, Linear\n",
    "\n",
    "from torch_geometric.nn.inits import zeros\n",
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.utils.scatter import scatter_argmax\n",
    "\n",
    "TGNMessageStoreType = Dict[int, Tuple[Tensor, Tensor, Tensor, Tensor]]\n",
    "\n",
    "\n",
    "class TGNMemory(torch.nn.Module):\n",
    "    r\"\"\"The Temporal Graph Network (TGN) memory model from the\n",
    "    `\"Temporal Graph Networks for Deep Learning on Dynamic Graphs\"\n",
    "    <https://arxiv.org/abs/2006.10637>`_ paper.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using TGN, see `examples/tgn.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        tgn.py>`_.\n",
    "\n",
    "    Args:\n",
    "        num_nodes (int): The number of nodes to save memories for.\n",
    "        raw_msg_dim (int): The raw message dimensionality.\n",
    "        memory_dim (int): The hidden memory dimensionality.\n",
    "        time_dim (int): The time encoding dimensionality.\n",
    "        message_module (torch.nn.Module): The message function which\n",
    "            combines source and destination node memory embeddings, the raw\n",
    "            message and the time encoding.\n",
    "        aggregator_module (torch.nn.Module): The message aggregator function\n",
    "            which aggregates messages to the same destination into a single\n",
    "            representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes: int, raw_msg_dim: int, memory_dim: int,\n",
    "                 time_dim: int, message_module: Callable,\n",
    "                 aggregator_module: Callable):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.raw_msg_dim = raw_msg_dim\n",
    "        self.memory_dim = memory_dim\n",
    "        self.time_dim = time_dim\n",
    "\n",
    "        self.msg_s_module = message_module\n",
    "        self.msg_d_module = copy.deepcopy(message_module)\n",
    "        self.aggr_module = aggregator_module\n",
    "        self.time_enc = TimeEncoder(time_dim)\n",
    "        self.gru = GRUCell(message_module.out_channels, memory_dim)\n",
    "\n",
    "        self.register_buffer('memory', torch.empty(num_nodes, memory_dim))\n",
    "        last_update = torch.empty(self.num_nodes, dtype=torch.long)\n",
    "        self.register_buffer('last_update', last_update)\n",
    "        self.register_buffer('_assoc', torch.empty(num_nodes,\n",
    "                                                   dtype=torch.long))\n",
    "\n",
    "        self.msg_s_store = {}\n",
    "        self.msg_d_store = {}\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.time_enc.lin.weight.device\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        if hasattr(self.msg_s_module, 'reset_parameters'):\n",
    "            self.msg_s_module.reset_parameters()\n",
    "        if hasattr(self.msg_d_module, 'reset_parameters'):\n",
    "            self.msg_d_module.reset_parameters()\n",
    "        if hasattr(self.aggr_module, 'reset_parameters'):\n",
    "            self.aggr_module.reset_parameters()\n",
    "        self.time_enc.reset_parameters()\n",
    "        self.gru.reset_parameters()\n",
    "        self.reset_state()\n",
    "\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"Resets the memory to its initial state.\"\"\"\n",
    "        zeros(self.memory)\n",
    "        zeros(self.last_update)\n",
    "        self._reset_message_store()\n",
    "\n",
    "\n",
    "    def detach(self):\n",
    "        \"\"\"Detaches the memory from gradient computation.\"\"\"\n",
    "        self.memory.detach_()\n",
    "\n",
    "\n",
    "    def forward(self, n_id: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Returns, for all nodes :obj:`n_id`, their current memory and their\n",
    "        last updated timestamp.\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            memory, last_update = self._get_updated_memory(n_id)\n",
    "        else:\n",
    "            memory, last_update = self.memory[n_id], self.last_update[n_id]\n",
    "\n",
    "        return memory, last_update\n",
    "\n",
    "\n",
    "    def update_state(self, src: Tensor, dst: Tensor, t: Tensor,\n",
    "                     raw_msg: Tensor):\n",
    "        \"\"\"Updates the memory with newly encountered interactions\n",
    "        :obj:`(src, dst, t, raw_msg)`.\n",
    "        \"\"\"\n",
    "        n_id = torch.cat([src, dst]).unique()\n",
    "\n",
    "        if self.training:\n",
    "            self._update_memory(n_id)\n",
    "            self._update_msg_store(src, dst, t, raw_msg, self.msg_s_store)\n",
    "            self._update_msg_store(dst, src, t, raw_msg, self.msg_d_store)\n",
    "        else:\n",
    "            self._update_msg_store(src, dst, t, raw_msg, self.msg_s_store)\n",
    "            self._update_msg_store(dst, src, t, raw_msg, self.msg_d_store)\n",
    "            self._update_memory(n_id)\n",
    "\n",
    "\n",
    "    def _reset_message_store(self):\n",
    "        i = self.memory.new_empty((0, ), device=self.device, dtype=torch.long)\n",
    "        msg = self.memory.new_empty((0, self.raw_msg_dim), device=self.device)\n",
    "        # Message store format: (src, dst, t, msg)\n",
    "        self.msg_s_store = {j: (i, i, i, msg) for j in range(self.num_nodes)}\n",
    "        self.msg_d_store = {j: (i, i, i, msg) for j in range(self.num_nodes)}\n",
    "\n",
    "    def _update_memory(self, n_id: Tensor):\n",
    "        memory, last_update = self._get_updated_memory(n_id)\n",
    "        self.memory[n_id] = memory\n",
    "        self.last_update[n_id] = last_update\n",
    "\n",
    "    def _get_updated_memory(self, n_id: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        self._assoc[n_id] = torch.arange(n_id.size(0), device=n_id.device)\n",
    "\n",
    "        # Compute messages (src -> dst).\n",
    "        msg_s, t_s, src_s, dst_s = self._compute_msg(n_id, self.msg_s_store,\n",
    "                                                     self.msg_s_module)\n",
    "\n",
    "        # Compute messages (dst -> src).\n",
    "        msg_d, t_d, src_d, dst_d = self._compute_msg(n_id, self.msg_d_store,\n",
    "                                                     self.msg_d_module)\n",
    "\n",
    "        # Aggregate messages.\n",
    "        idx = torch.cat([src_s, src_d], dim=0)\n",
    "        msg = torch.cat([msg_s, msg_d], dim=0)\n",
    "        t = torch.cat([t_s, t_d], dim=0)\n",
    "        aggr = self.aggr_module(msg, self._assoc[idx], t, n_id.size(0))\n",
    "\n",
    "        # Get local copy of updated memory.\n",
    "        memory = self.gru(aggr, self.memory[n_id])\n",
    "\n",
    "        # Get local copy of updated `last_update`.\n",
    "        dim_size = self.last_update.size(0)\n",
    "        last_update = scatter(t, idx, 0, dim_size, reduce='max')[n_id]\n",
    "\n",
    "        return memory, last_update\n",
    "\n",
    "    def _update_msg_store(self, src: Tensor, dst: Tensor, t: Tensor,\n",
    "                          raw_msg: Tensor, msg_store: TGNMessageStoreType):\n",
    "        n_id, perm = src.sort()\n",
    "        n_id, count = n_id.unique_consecutive(return_counts=True)\n",
    "        for i, idx in zip(n_id.tolist(), perm.split(count.tolist())):\n",
    "            msg_store[i] = (src[idx], dst[idx], t[idx], raw_msg[idx])\n",
    "\n",
    "    def _compute_msg(self, n_id: Tensor, msg_store: TGNMessageStoreType,\n",
    "                     msg_module: Callable):\n",
    "        data = [msg_store[i] for i in n_id.tolist()]\n",
    "        src, dst, t, raw_msg = list(zip(*data))\n",
    "        src = torch.cat(src, dim=0)\n",
    "        dst = torch.cat(dst, dim=0)\n",
    "        t = torch.cat(t, dim=0)\n",
    "        raw_msg = torch.cat(raw_msg, dim=0)\n",
    "        t_rel = t - self.last_update[src]\n",
    "        t_enc = self.time_enc(t_rel.to(raw_msg.dtype))\n",
    "\n",
    "        msg = msg_module(self.memory[src], self.memory[dst], raw_msg, t_enc)\n",
    "\n",
    "        return msg, t, src, dst\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        \"\"\"Sets the module in training mode.\"\"\"\n",
    "        if self.training and not mode:\n",
    "            # Flush message store to memory in case we just entered eval mode.\n",
    "            self._update_memory(\n",
    "                torch.arange(self.num_nodes, device=self.memory.device))\n",
    "            self._reset_message_store()\n",
    "        super().train(mode)\n",
    "\n",
    "\n",
    "class IdentityMessage(torch.nn.Module):\n",
    "    def __init__(self, raw_msg_dim: int, memory_dim: int, time_dim: int):\n",
    "        super().__init__()\n",
    "        self.out_channels = raw_msg_dim + 2 * memory_dim + time_dim\n",
    "\n",
    "    def forward(self, z_src: Tensor, z_dst: Tensor, raw_msg: Tensor,\n",
    "                t_enc: Tensor):\n",
    "        return torch.cat([z_src, z_dst, raw_msg, t_enc], dim=-1)\n",
    "\n",
    "\n",
    "class LastAggregator(torch.nn.Module):\n",
    "    def forward(self, msg: Tensor, index: Tensor, t: Tensor, dim_size: int):\n",
    "        argmax = scatter_argmax(t, index, dim=0, dim_size=dim_size)\n",
    "        out = msg.new_zeros((dim_size, msg.size(-1)))\n",
    "        mask = argmax < msg.size(0)  # Filter items with at least one entry.\n",
    "        out[mask] = msg[argmax[mask]]\n",
    "        return out\n",
    "\n",
    "\n",
    "class MeanAggregator(torch.nn.Module):\n",
    "    def forward(self, msg: Tensor, index: Tensor, t: Tensor, dim_size: int):\n",
    "        return scatter(msg, index, dim=0, dim_size=dim_size, reduce='mean')\n",
    "\n",
    "\n",
    "class TimeEncoder(torch.nn.Module):\n",
    "    def __init__(self, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(1, out_channels)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "\n",
    "    def forward(self, t: Tensor) -> Tensor:\n",
    "        return self.lin(t.view(-1, 1)).cos()\n",
    "\n",
    "\n",
    "class LastNeighborLoader:\n",
    "    def __init__(self, num_nodes: int, size: int, device=None):\n",
    "        self.size = size\n",
    "\n",
    "        self.neighbors = torch.empty((num_nodes, size), dtype=torch.long,\n",
    "                                     device=device)\n",
    "        self.e_id = torch.empty((num_nodes, size), dtype=torch.long,\n",
    "                                device=device)\n",
    "        self._assoc = torch.empty(num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        self.reset_state()\n",
    "\n",
    "    def __call__(self, n_id: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        neighbors = self.neighbors[n_id]\n",
    "        nodes = n_id.view(-1, 1).repeat(1, self.size)\n",
    "        e_id = self.e_id[n_id]\n",
    "\n",
    "        # Filter invalid neighbors (identified by `e_id < 0`).\n",
    "        mask = e_id >= 0\n",
    "        neighbors, nodes, e_id = neighbors[mask], nodes[mask], e_id[mask]\n",
    "\n",
    "        # Relabel node indices.\n",
    "        n_id = torch.cat([n_id, neighbors]).unique()\n",
    "        self._assoc[n_id] = torch.arange(n_id.size(0), device=n_id.device)\n",
    "        neighbors, nodes = self._assoc[neighbors], self._assoc[nodes]\n",
    "\n",
    "        return n_id, torch.stack([neighbors, nodes]), e_id\n",
    "\n",
    "    def insert(self, src: Tensor, dst: Tensor):\n",
    "        # Inserts newly encountered interactions into an ever-growing\n",
    "        # (undirected) temporal graph.\n",
    "\n",
    "        # Collect central nodes, their neighbors and the current event ids.\n",
    "        neighbors = torch.cat([src, dst], dim=0)\n",
    "        nodes = torch.cat([dst, src], dim=0)\n",
    "        e_id = torch.arange(self.cur_e_id, self.cur_e_id + src.size(0),\n",
    "                            device=src.device).repeat(2)\n",
    "        self.cur_e_id += src.numel()\n",
    "\n",
    "        # Convert newly encountered interaction ids so that they point to\n",
    "        # locations of a \"dense\" format of shape [num_nodes, size].\n",
    "        nodes, perm = nodes.sort()\n",
    "        neighbors, e_id = neighbors[perm], e_id[perm]\n",
    "\n",
    "        n_id = nodes.unique()\n",
    "        self._assoc[n_id] = torch.arange(n_id.numel(), device=n_id.device)\n",
    "\n",
    "        dense_id = torch.arange(nodes.size(0), device=nodes.device) % self.size\n",
    "        dense_id += self._assoc[nodes].mul_(self.size)\n",
    "\n",
    "        dense_e_id = e_id.new_full((n_id.numel() * self.size, ), -1)\n",
    "        dense_e_id[dense_id] = e_id\n",
    "        dense_e_id = dense_e_id.view(-1, self.size)\n",
    "\n",
    "        dense_neighbors = e_id.new_empty(n_id.numel() * self.size)\n",
    "        dense_neighbors[dense_id] = neighbors\n",
    "        dense_neighbors = dense_neighbors.view(-1, self.size)\n",
    "\n",
    "        # Collect new and old interactions...\n",
    "        e_id = torch.cat([self.e_id[n_id, :self.size], dense_e_id], dim=-1)\n",
    "        neighbors = torch.cat(\n",
    "            [self.neighbors[n_id, :self.size], dense_neighbors], dim=-1)\n",
    "\n",
    "        # And sort them based on `e_id`.\n",
    "        e_id, perm = e_id.topk(self.size, dim=-1)\n",
    "        self.e_id[n_id] = e_id\n",
    "        self.neighbors[n_id] = torch.gather(neighbors, 1, perm)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.cur_e_id = 0\n",
    "        self.e_id.fill_(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166f7023-1b15-4fa9-ad08-770aae682f08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalData(src=[411749], dst=[411749], t=[411749], msg=[411749, 4], y=[411749])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = torch.load(\"data/junyi/graph.pt\")\n",
    "data = torch.load(\"data/act-mooc/graph.pt\")\n",
    "del data[('resource', 'rev_accesses', 'user')]\n",
    "data_hom = data.to_homogeneous()\n",
    "data_temp = TemporalData(\n",
    "    src=data_hom.edge_index[0,:].to(torch.long),\n",
    "    dst=data_hom.edge_index[1,:].to(torch.long),\n",
    "    t=data_hom.time.to(torch.long),\n",
    "    msg=data_hom.edge_attr.to(torch.float),\n",
    "    y=data_hom.edge_y.to(torch.long)\n",
    ")\n",
    "data = data_temp\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4227a86c-04ed-4ec9-a373-15b24d83de85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For small datasets, we can put the whole dataset on GPU and thus avoid\n",
    "# expensive memory transfer costs for mini-batches:\n",
    "data = data.to(device)\n",
    "\n",
    "train_data, val_data, test_data = data.train_val_test_split(\n",
    "    val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "train_loader = TemporalDataLoader(\n",
    "    train_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "val_loader = TemporalDataLoader(\n",
    "    val_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "test_loader = TemporalDataLoader(\n",
    "    test_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "neighbor_loader = LastNeighborLoader(data.num_nodes, size=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac53cbd6-de2f-4061-9a91-cd0e63e113b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class GraphAttentionEmbedding(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        edge_dim = msg_dim + time_enc.out_channels\n",
    "        self.conv = TransformerConv(in_channels, out_channels // 2, heads=2,\n",
    "                                    dropout=0.1, edge_dim=edge_dim)\n",
    "\n",
    "    def forward(self, x, last_update, edge_index, t, msg):\n",
    "        rel_t = last_update[edge_index[0]] - t\n",
    "        rel_t_enc = self.time_enc(rel_t.to(x.dtype))\n",
    "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
    "        return self.conv(x, edge_index, edge_attr)\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.lin_src = Linear(in_channels, in_channels)\n",
    "        self.lin_dst = Linear(in_channels, in_channels)\n",
    "        self.lin_final = Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        h = self.lin_src(z_src) + self.lin_dst(z_dst)\n",
    "        h = h.relu()\n",
    "        return self.lin_final(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c20bb4c-ea04-431b-b8f5-21f876e9995a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "memory_dim = time_dim = embedding_dim = 100\n",
    "\n",
    "memory = TGNMemory(\n",
    "    data.num_nodes,\n",
    "    data.msg.size(-1),\n",
    "    memory_dim,\n",
    "    time_dim,\n",
    "    message_module=IdentityMessage(data.msg.size(-1), memory_dim, time_dim),\n",
    "    aggregator_module=LastAggregator(),\n",
    ").to(device)\n",
    "\n",
    "gnn = GraphAttentionEmbedding(\n",
    "    in_channels=memory_dim,\n",
    "    out_channels=embedding_dim,\n",
    "    msg_dim=data.msg.size(-1),\n",
    "    time_enc=memory.time_enc,\n",
    ").to(device)\n",
    "\n",
    "link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    set(memory.parameters()) | set(gnn.parameters())\n",
    "    | set(link_pred.parameters()), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Helper vector to map global node indices to local ones.\n",
    "assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    memory.train()\n",
    "    gnn.train()\n",
    "    link_pred.train()\n",
    "\n",
    "    memory.reset_state()  # Start with a fresh memory.\n",
    "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "    total_loss = 0\n",
    "    batches = 0\n",
    "    for batch in train_loader:\n",
    "        batches += 1\n",
    "        if batches % 100 == 0:\n",
    "            print(batches)\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        # Get updated memory of all nodes involved in the computation.\n",
    "        z, last_update = memory(n_id)\n",
    "\n",
    "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "                data.msg[e_id].to(device))\n",
    "        pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "        neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "        # we are actually interested in the edge labels not existence\n",
    "        loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "        loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "\n",
    "        # Update memory and neighbor loader with ground-truth state.\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        memory.detach()\n",
    "        total_loss += float(loss) * batch.num_events\n",
    "\n",
    "    return total_loss / train_data.num_events\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    memory.eval()\n",
    "    gnn.eval()\n",
    "    link_pred.eval()\n",
    "\n",
    "    #torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
    "\n",
    "    aps, aucs = [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "        \n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "                data.msg[e_id].to(device))\n",
    "        pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "        neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "        y_pred = torch.cat([pos_out, neg_out], dim=0).sigmoid().cpu()\n",
    "        y_true = torch.cat(\n",
    "            [torch.ones(pos_out.size(0)),\n",
    "             torch.zeros(neg_out.size(0))], dim=0)\n",
    "\n",
    "        aps.append(average_precision_score(y_true, y_pred))\n",
    "        aucs.append(roc_auc_score(y_true, y_pred))\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "    return float(torch.tensor(aps).mean()), float(torch.tensor(aucs).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ddcdf6-f42b-40b4-b381-8ea1d107c7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a4027b-fd1e-44ba-a2eb-bc07c3af4e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "Epoch: 01, Loss: 0.6423\n"
     ]
    },
    {
     "ename": "<class 'RuntimeError'>",
     "evalue": "The size of tensor a (1295) must match the size of tensor b (264) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m val_ap, val_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m test_ap, test_auc \u001b[38;5;241m=\u001b[39m test(test_loader)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal AP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_ap\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/mooc/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 96\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     93\u001b[0m pos_out \u001b[38;5;241m=\u001b[39m link_pred(z[assoc[batch\u001b[38;5;241m.\u001b[39msrc]], z[assoc[batch\u001b[38;5;241m.\u001b[39mdst]])\n\u001b[1;32m     94\u001b[0m neg_out \u001b[38;5;241m=\u001b[39m link_pred(z[assoc[batch\u001b[38;5;241m.\u001b[39msrc]], z[assoc[batch\u001b[38;5;241m.\u001b[39mneg_dst]])\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28mprint\u001b[39m((\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43me_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_update\u001b[49m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     97\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([pos_out, neg_out], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msigmoid()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     98\u001b[0m y_true \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     99\u001b[0m     [torch\u001b[38;5;241m.\u001b[39mones(pos_out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m    100\u001b[0m      torch\u001b[38;5;241m.\u001b[39mzeros(neg_out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1295) must match the size of tensor b (264) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "    val_ap, val_auc = test(val_loader)\n",
    "    test_ap, test_auc = test(test_loader)\n",
    "    print(f'Val AP: {val_ap:.4f}, Val AUC: {val_auc:.4f}')\n",
    "    print(f'Test AP: {test_ap:.4f}, Test AUC: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f08d0-690a-4b5d-849a-240334abd020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51267464-1ccf-4de5-bbf5-12b2dfb426ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
