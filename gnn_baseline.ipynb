{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2c8385e9-dc0f-4cbc-ae4c-da8a5c918176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_default_dtype(torch.float32)\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8f4db4ae-13b1-4d73-991d-7f4dee21d131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc4dcd4a-b913-46ab-ae4a-b5d7eb682b8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = torch.load(\"data/act-mooc/graph.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "39f2d206-4bde-4025-95f0-e00518f5b99c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data = torch.load(\"data/junyi/graph.pt\")\n",
    "#del data[('resource', 'rev_accesses', 'user')]\n",
    "data_hom = data.to_homogeneous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "759e88e9-306e-4559-b399-bfb8b74769d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 823498], node_id=[7144], edge_attr=[823498, 4], time=[823498], edge_y=[823498], node_type=[7144], edge_type=[823498], x=[7144, 1])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_hom\n",
    "data.x = torch.randn(data.num_nodes, 1)\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "54f4923e-4dad-406a-9b6c-2ba418952522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_attr =data.edge_attr.float()\n",
    "data.time =data.time.float()\n",
    "\n",
    "data.time.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0b0bfb00-4a60-4e29-aab7-16f56d457ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7144, 16])\n",
      "torch.Size([823498, 1])\n"
     ]
    }
   ],
   "source": [
    "class TimeEncoder(torch.nn.Module):\n",
    "    def __init__(self, time_dim):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.time_lin = Linear(1, time_dim)\n",
    "\n",
    "    def forward(self, t: Tensor):\n",
    "        # embed time and add to edge_attr\n",
    "        return self.time_lin(t.view(-1, 1)).cos()\n",
    "\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, time_enc):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, edge_dim=edge_dim)\n",
    "        self.conv2 = GATConv(hidden_channels, out_channels, edge_dim=edge_dim)\n",
    "        self.time_enc = time_enc\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, t: Tensor) -> Tensor:\n",
    "        # x: Node feature matrix of shape [num_nodes, in_channels]\n",
    "        # edge_index: Graph connectivity matrix of shape [2, num_edges]\n",
    "        # edge_attr: Edge features\n",
    "        # t: Timestamp of edges\n",
    "        time_enc = self.time_enc(t)\n",
    "        edge_attr = torch.cat([time_enc, edge_attr], dim=-1)\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        dim = 2 * in_channels + time_enc.time_dim\n",
    "        self.lin = Linear(dim, dim)\n",
    "        self.lin_final = Linear(dim, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst, t):\n",
    "        time_enc = self.time_enc(t)\n",
    "        input = torch.cat([z_src, z_dst, time_enc], dim=-1)\n",
    "        h = self.lin(input)\n",
    "        h = h.relu()\n",
    "        return self.lin_final(h)\n",
    "\n",
    "\n",
    "emd_dim = hidden_dim = time_dim = 16\n",
    "\n",
    "time_enc = TimeEncoder(time_dim).to(device)\n",
    "gnn = GATModel(data.x.size(1), hidden_dim, emd_dim, time_dim+data.edge_attr.size(1), time_enc).to(device)\n",
    "link_pred = LinkPredictor(emd_dim, time_enc).to(device)\n",
    "\n",
    "# Test forward run of the models\n",
    "embs = gnn(data.x, data.edge_index, data.edge_attr, data.time)\n",
    "print(embs.shape)\n",
    "link_preds = link_pred(embs[data.edge_index[0]], embs[data.edge_index[1]], data.time)\n",
    "print(link_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "39173821-a4bf-4a98-8701-0d4572a7b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(set(time_enc.parameters()) | set(gnn.parameters()) | set(link_pred.parameters()), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bb196a3e-07b4-4b21-9d04-031d96fc6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(gnn, link_pred, data):\n",
    "    gnn.eval()\n",
    "    link_pred.eval()\n",
    "    node_embs = gnn(data.x, data.edge_index, data.edge_attr, data.time)\n",
    "    link_preds = link_pred(node_embs[data.edge_index[0]], node_embs[data.edge_index[1]], data.time).sigmoid()\n",
    "    #RocCurveDisplay.from_predictions(data.edge_y, link_preds)\n",
    "    #plt.show()\n",
    "    return roc_auc_score(data.edge_y.cpu().numpy(), link_preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6339dd72-fbef-47f2-baa0-1c66f7cd8817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.6937603642696201, Test AUC: 0.498769654065793\n",
      "Epoch: 1, Train Loss: 0.6945780535233474, Test AUC: 0.5068827445771643\n",
      "Epoch: 2, Train Loss: 0.6932498224727709, Test AUC: 0.5034052086940485\n",
      "Epoch: 3, Train Loss: 0.693683015662305, Test AUC: 0.5113500072179161\n",
      "Epoch: 4, Train Loss: 0.6926424382397065, Test AUC: 0.5071598980185239\n",
      "Epoch: 5, Train Loss: 0.6932940874504707, Test AUC: 0.5124394207090478\n",
      "Epoch: 6, Train Loss: 0.6927942042985717, Test AUC: 0.5093633135861677\n",
      "Epoch: 7, Train Loss: 0.6930127761544214, Test AUC: 0.512417262688953\n",
      "Epoch: 8, Train Loss: 0.6932954716262995, Test AUC: 0.5192316627745428\n",
      "Epoch: 9, Train Loss: 0.6924372624923244, Test AUC: 0.5172259100331127\n",
      "Epoch: 10, Train Loss: 0.692597188023448, Test AUC: 0.5162985950823489\n",
      "Epoch: 11, Train Loss: 0.6929247273750987, Test AUC: 0.52617324939778\n",
      "Epoch: 12, Train Loss: 0.6922663260362717, Test AUC: 0.5280391530139831\n",
      "Epoch: 13, Train Loss: 0.6919736347255832, Test AUC: 0.5232051721997351\n",
      "Epoch: 14, Train Loss: 0.6924654091944284, Test AUC: 0.5318851655957402\n",
      "Epoch: 15, Train Loss: 0.6916994690788915, Test AUC: 0.5305601208956295\n",
      "Epoch: 16, Train Loss: 0.6921088429706939, Test AUC: 0.5381000683219896\n",
      "Epoch: 17, Train Loss: 0.6916739744971658, Test AUC: 0.5429367175397877\n",
      "Epoch: 18, Train Loss: 0.6915848928724612, Test AUC: 0.5456202996802177\n",
      "Epoch: 19, Train Loss: 0.6914442849855259, Test AUC: 0.5543717046558432\n",
      "Epoch: 20, Train Loss: 0.690526659292649, Test AUC: 0.5530227031423786\n",
      "Epoch: 21, Train Loss: 0.6908012563926756, Test AUC: 0.5511433953718603\n",
      "Epoch: 22, Train Loss: 0.6914438332838844, Test AUC: 0.562461408818814\n",
      "Epoch: 23, Train Loss: 0.6904473659031911, Test AUC: 0.5523827821010142\n",
      "Epoch: 24, Train Loss: 0.6910949871508634, Test AUC: 0.5543029312409827\n",
      "Epoch: 25, Train Loss: 0.6907906300752239, Test AUC: 0.5625715916550081\n",
      "Epoch: 26, Train Loss: 0.6896591132599036, Test AUC: 0.5652056432606616\n",
      "Epoch: 27, Train Loss: 0.6900994526823607, Test AUC: 0.5587127565443409\n",
      "Epoch: 28, Train Loss: 0.6905556060829595, Test AUC: 0.5640873951603355\n",
      "Epoch: 29, Train Loss: 0.6897091961891697, Test AUC: 0.5766938540405234\n",
      "Epoch: 30, Train Loss: 0.6884233902724559, Test AUC: 0.5676526972085537\n",
      "Epoch: 31, Train Loss: 0.6894354042181386, Test AUC: 0.58707540036348\n",
      "Epoch: 32, Train Loss: 0.6873503164751286, Test AUC: 0.5789149189568032\n",
      "Epoch: 33, Train Loss: 0.6891286484571311, Test AUC: 0.571865395764397\n",
      "Epoch: 34, Train Loss: 0.6893534565849396, Test AUC: 0.5861995973800274\n",
      "Epoch: 35, Train Loss: 0.6870056965037451, Test AUC: 0.5793773594905562\n",
      "Epoch: 36, Train Loss: 0.6878628503520681, Test AUC: 0.5789775364779377\n",
      "Epoch: 37, Train Loss: 0.6882368696229239, Test AUC: 0.5898690866136784\n",
      "Epoch: 38, Train Loss: 0.6854506616618193, Test AUC: 0.591708962775792\n",
      "Epoch: 39, Train Loss: 0.6880310418958552, Test AUC: 0.577437919963178\n",
      "Epoch: 40, Train Loss: 0.688509852392513, Test AUC: 0.5894640831156853\n",
      "Epoch: 41, Train Loss: 0.6858350021028923, Test AUC: 0.6014059154106162\n",
      "Epoch: 42, Train Loss: 0.6831837022142, Test AUC: 0.5987909621270402\n",
      "Epoch: 43, Train Loss: 0.6827636851805841, Test AUC: 0.6098431877702148\n",
      "Epoch: 44, Train Loss: 0.6833066384832166, Test AUC: 0.5977177536110186\n",
      "Epoch: 45, Train Loss: 0.6841871153837664, Test AUC: 0.607292608798524\n",
      "Epoch: 46, Train Loss: 0.6837567791722788, Test AUC: 0.6025346990522628\n",
      "Epoch: 47, Train Loss: 0.6842543775521328, Test AUC: 0.5955591693495295\n",
      "Epoch: 48, Train Loss: 0.6815462048984272, Test AUC: 0.6125248892992134\n",
      "Epoch: 49, Train Loss: 0.6816706085338878, Test AUC: 0.6113353223716654\n",
      "Epoch: 50, Train Loss: 0.6789707976393515, Test AUC: 0.5981128824473816\n",
      "Epoch: 51, Train Loss: 0.6795650337742939, Test AUC: 0.6160943218454942\n",
      "Epoch: 52, Train Loss: 0.6794328997651194, Test AUC: 0.5974806964281763\n",
      "Epoch: 53, Train Loss: 0.6802539756589353, Test AUC: 0.5977468595398303\n",
      "Epoch: 54, Train Loss: 0.6818591665634998, Test AUC: 0.610529028110907\n",
      "Epoch: 55, Train Loss: 0.6786852222652144, Test AUC: 0.6193654003914595\n",
      "Epoch: 56, Train Loss: 0.6761454765535618, Test AUC: 0.6130324310259775\n",
      "Epoch: 57, Train Loss: 0.6735278608434225, Test AUC: 0.6222040858824396\n",
      "Epoch: 58, Train Loss: 0.6725825659104017, Test AUC: 0.6202152090251338\n",
      "Epoch: 59, Train Loss: 0.6748825478167316, Test AUC: 0.6090097261057694\n",
      "Epoch: 60, Train Loss: 0.6741475049413075, Test AUC: 0.6227125153929316\n",
      "Epoch: 61, Train Loss: 0.6744119408911491, Test AUC: 0.6289245311065236\n",
      "Epoch: 62, Train Loss: 0.6680169894951932, Test AUC: 0.6356207993999765\n",
      "Epoch: 63, Train Loss: 0.6671923077779651, Test AUC: 0.6379464862314255\n",
      "Epoch: 64, Train Loss: 0.6638143074237379, Test AUC: 0.6392047294477453\n",
      "Epoch: 65, Train Loss: 0.6649786810272059, Test AUC: 0.634104648337085\n",
      "Epoch: 66, Train Loss: 0.6663347781113355, Test AUC: 0.64032496953779\n",
      "Epoch: 67, Train Loss: 0.6620563973804506, Test AUC: 0.6302486339550448\n",
      "Epoch: 68, Train Loss: 0.6664247979211061, Test AUC: 0.6418996990942076\n",
      "Epoch: 69, Train Loss: 0.6619382096553337, Test AUC: 0.6428609792191446\n",
      "Epoch: 70, Train Loss: 0.6618101007341848, Test AUC: 0.6427277985389048\n",
      "Epoch: 71, Train Loss: 0.664198787881922, Test AUC: 0.6390831485483356\n",
      "Epoch: 72, Train Loss: 0.6626471414361781, Test AUC: 0.6630935050717959\n",
      "Epoch: 73, Train Loss: 0.6517393512122673, Test AUC: 0.6550498931197374\n",
      "Epoch: 74, Train Loss: 0.6542114863051119, Test AUC: 0.6478823328482124\n",
      "Epoch: 75, Train Loss: 0.6597587520071565, Test AUC: 0.6400100224350527\n",
      "Epoch: 76, Train Loss: 0.6584257743880473, Test AUC: 0.6519410874584848\n",
      "Epoch: 77, Train Loss: 0.6540322079476926, Test AUC: 0.6559877291333982\n",
      "Epoch: 78, Train Loss: 0.6553930731274259, Test AUC: 0.660881717355966\n",
      "Epoch: 79, Train Loss: 0.6483351346187223, Test AUC: 0.6668187777846294\n",
      "Epoch: 80, Train Loss: 0.645293237667222, Test AUC: 0.6681890772093634\n",
      "Epoch: 81, Train Loss: 0.6458484707598332, Test AUC: 0.6710923477034487\n",
      "Epoch: 82, Train Loss: 0.6429750530442142, Test AUC: 0.6745601135164601\n",
      "Epoch: 83, Train Loss: 0.6417371981530562, Test AUC: 0.6675893532476194\n",
      "Epoch: 84, Train Loss: 0.6426224227880956, Test AUC: 0.6669654128412144\n",
      "Epoch: 85, Train Loss: 0.6477053180047545, Test AUC: 0.6854603795121196\n",
      "Epoch: 86, Train Loss: 0.634665492737395, Test AUC: 0.6734163890470252\n",
      "Epoch: 87, Train Loss: 0.6432215129974698, Test AUC: 0.6871655346255054\n",
      "Epoch: 88, Train Loss: 0.6361987884670053, Test AUC: 0.6837859494978678\n",
      "Epoch: 89, Train Loss: 0.634767974545218, Test AUC: 0.6911551057497451\n",
      "Epoch: 90, Train Loss: 0.6302439192906311, Test AUC: 0.7005990830049675\n",
      "Epoch: 91, Train Loss: 0.623962124127508, Test AUC: 0.6860975068210837\n",
      "Epoch: 92, Train Loss: 0.6315761007740429, Test AUC: 0.6961942425020461\n",
      "Epoch: 93, Train Loss: 0.625712563380401, Test AUC: 0.6941744242741604\n",
      "Epoch: 94, Train Loss: 0.6294883072981633, Test AUC: 0.6996343524154056\n",
      "Epoch: 95, Train Loss: 0.6296980223791152, Test AUC: 0.7016674383083047\n",
      "Epoch: 96, Train Loss: 0.6253081905811089, Test AUC: 0.7020491144273083\n",
      "Epoch: 97, Train Loss: 0.6250938593826371, Test AUC: 0.7045231350415835\n",
      "Epoch: 98, Train Loss: 0.6210767173432079, Test AUC: 0.702625491856316\n",
      "Epoch: 99, Train Loss: 0.620140805781626, Test AUC: 0.7073003407741815\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):\n",
    "    gnn.train()\n",
    "    link_pred.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    node_embs = gnn(data.x, data.edge_index, data.edge_attr, data.time)\n",
    "\n",
    "    # take all 1 edges and sample the same number of 0 edges from edge_index\n",
    "    positive_edges = data.edge_index[:, data.edge_y == 1]\n",
    "    negative_indices = torch.nonzero(data.edge_y == 0).squeeze()\n",
    "    \n",
    "    negative_indices = negative_indices[torch.randperm(negative_indices.size(0))][:positive_edges.size(1)]\n",
    "    negative_edges = data.edge_index[:, negative_indices]\n",
    "    \n",
    "    all_edges = torch.cat([positive_edges, negative_edges], dim=1)\n",
    "    all_labels = torch.cat([torch.ones(positive_edges.shape[1]), \n",
    "                            torch.zeros(negative_edges.shape[1])], dim=0).double()\n",
    "    all_times = torch.cat([data.time[data.edge_y == 1], data.time[negative_indices]])\n",
    "    all_labels = all_labels.to(device)\n",
    "    \n",
    "    link_preds = link_pred(node_embs[all_edges[0]], node_embs[all_edges[1]], all_times).flatten()\n",
    "    \n",
    "    loss = criterion(link_preds, all_labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    test_auc = test(gnn, link_pred, data)\n",
    "    print(f'Epoch: {epoch}, Train Loss: {loss}, Test AUC: {test_auc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7dba23-1a7c-4b16-9196-d6d52f7cf3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
