{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8385e9-dc0f-4cbc-ae4c-da8a5c918176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch_geometric\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "#print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e2b8aa-45e0-4140-b061-cbed8bbacbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc4dcd4a-b913-46ab-ae4a-b5d7eb682b8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data = torch.load(\"data/act-mooc/graph.pt\")\n",
    "data = torch.load(\"data/junyi/graph.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f2d206-4bde-4025-95f0-e00518f5b99c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_hom = data.to_homogeneous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759e88e9-306e-4559-b399-bfb8b74769d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 32434622], node_id=[74460], edge_attr=[32434622, 6], time=[32434622], edge_y=[32434622], node_type=[74460], edge_type=[32434622], x=[74460, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_hom\n",
    "# no data features is implemented as just one random number drawn from normal\n",
    "data.x = torch.randn(data.num_nodes, 1)\n",
    "data.edge_attr = data.edge_attr.float()\n",
    "data.time = data.time.float()\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac7d35-9219-4242-929b-377c8f7a7085",
   "metadata": {},
   "source": [
    "node_type==1 are resources\n",
    "let's split randomly by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f1f40b-5aae-4f0a-b112-33dfc9157859",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nodes = data.node_id[data.node_type==0]\n",
    "user_nodes = user_nodes[torch.randperm(user_nodes.shape[0])]\n",
    "resource_nodes = data.node_id[data.node_type==1]\n",
    "\n",
    "lim_train = int(user_nodes.size(0) * 0.7)\n",
    "lim_val = int(user_nodes.size(0) * 0.85)\n",
    "train_nodes = user_nodes[:lim_train]\n",
    "val_nodes = user_nodes[lim_train:lim_val]\n",
    "test_nodes = user_nodes[lim_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac69202a-7264-4635-820b-dd90c10c60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(edge_index, nodes):\n",
    "    mask = torch.zeros(edge_index.size(1), dtype=torch.bool).to(device)\n",
    "    for node in nodes:\n",
    "        mask |= (edge_index[0] == node) | (edge_index[1] == node)\n",
    "    return mask\n",
    "\n",
    "def create_mask_in_batches(edge_index, nodes, batch_size):\n",
    "    mask = torch.zeros(edge_index.size(1), dtype=torch.bool, device=device)\n",
    "    for i in range(0, len(nodes), batch_size):\n",
    "        batch_nodes = nodes[i:i + batch_size]\n",
    "        batch_mask = ((edge_index[0].unsqueeze(1) == batch_nodes).any(dim=1)) | \\\n",
    "                     ((edge_index[1].unsqueeze(1) == batch_nodes).any(dim=1))\n",
    "        mask |= batch_mask\n",
    "    return mask\n",
    "\n",
    "train_mask = create_mask_in_batches(data.edge_index, train_nodes, batch_size=256)\n",
    "val_mask = create_mask_in_batches(data.edge_index, val_nodes, batch_size=256)\n",
    "test_mask = create_mask_in_batches(data.edge_index, test_nodes, batch_size=256)\n",
    "\n",
    "def create_subset(data, mask):\n",
    "    subset = Data()\n",
    "    for key, item in data:\n",
    "        if key in ['node_id', 'node_type', 'x']:\n",
    "            subset[key] = item\n",
    "        elif key in ['edge_index']:\n",
    "            subset[key] = item[:,mask]\n",
    "        else:\n",
    "            subset[key] = item[mask]\n",
    "    return subset\n",
    "\n",
    "train_data = create_subset(data, train_mask)\n",
    "val_data = create_subset(data, val_mask)\n",
    "test_data = create_subset(data, test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb49e10-f293-4464-8a57-c7a68555bda5",
   "metadata": {},
   "source": [
    "This class iterates over batches of users and returns all edges they are connected with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee577e3-00f2-467e-a659-017f9106eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserLoader:\n",
    "    def __init__(self, data, user_nodes, batch_size=32):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "        self.user_nodes = user_nodes\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= len(self.user_nodes):\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "        \n",
    "        selected_nodes = self.user_nodes[self.index:self.index+self.batch_size]\n",
    "        mask = create_mask_in_batches(self.data.edge_index, selected_nodes, batch_size=256)\n",
    "        batch = create_subset(self.data, mask)\n",
    "        self.index += self.batch_size\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df6dc7a1-75cc-4ab0-b254-9aad86600d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2048\n",
    "train_loader = UserLoader(train_data, train_nodes, batch_size=batch_size)\n",
    "val_loader = UserLoader(val_data, val_nodes, batch_size=batch_size)\n",
    "test_loader = UserLoader(test_data, test_nodes, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0bfb00-4a60-4e29-aab7-16f56d457ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([74460, 100])\n",
      "torch.Size([857684, 1])\n"
     ]
    }
   ],
   "source": [
    "class TimeEncoder(torch.nn.Module):\n",
    "    def __init__(self, time_dim):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.time_lin = Linear(1, time_dim)\n",
    "\n",
    "    def forward(self, t: Tensor):\n",
    "        return self.time_lin(t.view(-1, 1)).cos()\n",
    "\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, time_enc):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, edge_dim=edge_dim)\n",
    "        self.conv2 = GATConv(hidden_channels, out_channels, edge_dim=edge_dim)\n",
    "        self.time_enc = time_enc\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, t: Tensor) -> Tensor:\n",
    "        # x: Node feature matrix of shape [num_nodes, in_channels]\n",
    "        # edge_index: Graph connectivity matrix of shape [2, num_edges]\n",
    "        # edge_attr: Edge features\n",
    "        # t: Timestamp of edges\n",
    "        time_enc = self.time_enc(t)\n",
    "        edge_attr = torch.cat([time_enc, edge_attr], dim=-1)\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        dim = 2 * in_channels + time_enc.time_dim\n",
    "        self.lin = Linear(dim, dim)\n",
    "        self.lin_final = Linear(dim, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst, t):\n",
    "        time_enc = self.time_enc(t)\n",
    "        input = torch.cat([z_src, z_dst, time_enc], dim=-1)\n",
    "        h = self.lin(input)\n",
    "        h = h.relu()\n",
    "        return self.lin_final(h)\n",
    "\n",
    "emd_dim = hidden_dim = time_dim = 100\n",
    "\n",
    "time_enc = TimeEncoder(time_dim).to(device)\n",
    "gnn = GATModel(data.x.size(1), hidden_dim, emd_dim, time_dim+data.edge_attr.size(1), time_enc).to(device)\n",
    "link_pred = LinkPredictor(emd_dim, time_enc).to(device)\n",
    "\n",
    "# Test forward run of the models\n",
    "batch = next(iter(train_loader)).to(device)\n",
    "train_loader = UserLoader(train_data, train_nodes, batch_size=batch_size) # reset\n",
    "embs = gnn(batch.x, batch.edge_index, batch.edge_attr, batch.time)\n",
    "print(embs.shape)\n",
    "link_preds = link_pred(embs[batch.edge_index[0]], embs[batch.edge_index[1]], batch.time)\n",
    "print(link_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb196a3e-07b4-4b21-9d04-031d96fc6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(gnn, link_pred):\n",
    "    gnn.eval()\n",
    "    link_pred.eval()\n",
    "    scores = []\n",
    "    for batch in tqdm(val_loader, desc='Validation Batches'):\n",
    "        node_embs = gnn(batch.x, batch.edge_index, batch.edge_attr, batch.time)\n",
    "        link_preds = link_pred(node_embs[batch.edge_index[0]], node_embs[batch.edge_index[1]], batch.time).sigmoid()\n",
    "        #RocCurveDisplay.from_predictions(batch.edge_y.cpu(), link_preds.cpu())\n",
    "        #plt.show()\n",
    "        scores += [roc_auc_score(batch.edge_y.cpu().numpy(), link_preds.cpu().numpy())]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6339dd72-fbef-47f2-baa0-1c66f7cd8817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 20it [00:15,  1.28it/s]\n",
      "Validation Batches: 6it [00:02,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.3535363674163818, Test AUC: 0.6941514756658488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 25it [00:19,  1.28it/s]\n",
      "Validation Batches: 6it [00:02,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.3568916320800781, Test AUC: 0.699999510903583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 25it [00:19,  1.28it/s]\n",
      "Validation Batches: 6it [00:02,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 1.3589524030685425, Test AUC: 0.687752449460473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 1it [00:01,  1.45s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m gnn\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      6\u001b[0m link_pred\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Batches\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      9\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mooc/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mUserLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m selected_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_nodes[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m     17\u001b[0m mask \u001b[38;5;241m=\u001b[39m create_mask_in_batches(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index, selected_nodes, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mcreate_subset\u001b[0;34m(data, mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m     subset[key] \u001b[38;5;241m=\u001b[39m item\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 34\u001b[0m     \u001b[43msubset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m item[:,mask]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     subset[key] \u001b[38;5;241m=\u001b[39m item[mask]\n",
      "File \u001b[0;32m~/.conda/envs/mooc/lib/python3.11/site-packages/torch_geometric/data/data.py:500\u001b[0m, in \u001b[0;36mData.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store[key]\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, value: Any):\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__delitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(set(time_enc.parameters()) | set(gnn.parameters()) | set(link_pred.parameters()), lr=0.0001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(0, 20):\n",
    "    gnn.train()\n",
    "    link_pred.train()\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc='Training Batches'):\n",
    "        batch.to(device)\n",
    "        # forward pass\n",
    "        node_embs = gnn(batch.x, batch.edge_index, batch.edge_attr, batch.time)\n",
    "    \n",
    "        # first predict for all dropout edges\n",
    "        positive_edges = batch.edge_index[:, batch.edge_y == 1]\n",
    "        pos_out = link_pred(node_embs[positive_edges[0]], node_embs[positive_edges[1]], batch.time[batch.edge_y == 1])\n",
    "        loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "\n",
    "        # sample the same number of 0 edges from edge_index\n",
    "        negative_indices = torch.nonzero(batch.edge_y == 0).squeeze()\n",
    "        negative_indices = negative_indices[torch.randperm(negative_indices.size(0))][:positive_edges.size(1)]\n",
    "        negative_edges = batch.edge_index[:, negative_indices]\n",
    "        neg_out = link_pred(node_embs[negative_edges[0]], node_embs[negative_edges[1]], batch.time[negative_indices])\n",
    "        loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "\n",
    "        # backward pass and gradient update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_auc = test(gnn, link_pred)\n",
    "    print(f'Epoch: {epoch}, Train Loss: {loss}, Test AUC: {test_auc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a7dba23-1a7c-4b16-9196-d6d52f7cf3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   8863 MiB |  10822 MiB |   4524 GiB |   4515 GiB |\n",
      "|       from large pool |   8858 MiB |  10818 MiB |   4524 GiB |   4515 GiB |\n",
      "|       from small pool |      4 MiB |      6 MiB |      0 GiB |      0 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   8863 MiB |  10822 MiB |   4524 GiB |   4515 GiB |\n",
      "|       from large pool |   8858 MiB |  10818 MiB |   4524 GiB |   4515 GiB |\n",
      "|       from small pool |      4 MiB |      6 MiB |      0 GiB |      0 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   8860 MiB |  10819 MiB |   4524 GiB |   4515 GiB |\n",
      "|       from large pool |   8855 MiB |  10815 MiB |   4524 GiB |   4515 GiB |\n",
      "|       from small pool |      4 MiB |      6 MiB |      0 GiB |      0 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  17804 MiB |  17804 MiB |  17804 MiB |      0 B   |\n",
      "|       from large pool |  17796 MiB |  17796 MiB |  17796 MiB |      0 B   |\n",
      "|       from small pool |      8 MiB |      8 MiB |      8 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   8938 MiB |   8938 MiB |    934 GiB |    925 GiB |\n",
      "|       from large pool |   8937 MiB |   8937 MiB |    934 GiB |    925 GiB |\n",
      "|       from small pool |      1 MiB |      2 MiB |      0 GiB |      0 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      83    |      86    |    1713    |    1630    |\n",
      "|       from large pool |      56    |      59    |    1587    |    1531    |\n",
      "|       from small pool |      27    |      32    |     126    |      99    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      83    |      86    |    1713    |    1630    |\n",
      "|       from large pool |      56    |      59    |    1587    |    1531    |\n",
      "|       from small pool |      27    |      32    |     126    |      99    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      14    |      14    |      14    |       0    |\n",
      "|       from large pool |      10    |      10    |      10    |       0    |\n",
      "|       from small pool |       4    |       4    |       4    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      24    |      24    |    1416    |    1392    |\n",
      "|       from large pool |      19    |      19    |    1358    |    1339    |\n",
      "|       from small pool |       5    |       6    |      58    |      53    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
